Rank,Title,Abstract,PDF Link,First Author Name,First Author H-index,Second Author Name,Second Author H-index,Predicted_Score,Publish Date,Topic,Summary
1,"=HYPERLINK(""http://arxiv.org/abs/2411.05141v1"", ""Audiobox TTA-RAG: Improving Zero-Shot and Few-Shot Text-To-Audio with
  Retrieval-Augmented Generation"")","Current leading Text-To-Audio (TTA) generation models suffer from degraded
performance on zero-shot and few-shot settings. It is often challenging to
generate high-quality audio for audio events that ...",http://arxiv.org/pdf/2411.05141v1.pdf,Mu Yang,57.0,Bowen Shi,19.0,104.83522,2024-11-07T19:50:28Z,RAG,"Current text-to-audio (TTA) models sometimes struggle to generate high-quality sounds for audio events that are rare or unseen in training data. Researchers from the University of Texas at Dallas and Meta AI have found a solution to this problem, proposing an innovative retrieval-augmented TTA approach called Audiobox TTA-RAG. This model employs the success of Retrieval-Augmented Generation (RAG) in large language model tasks to improve TTA process. This approach enhances TTA by adding relevant retrieved audio, effectively acting as supplementary context to guide the sound generation. The research found that this model could significantly enhance performance in zero-shot and few-shot TTA tests, and was able to generate audio that semantically aligns with the input text. This system does not require labelled audio database, making it adaptable to wider real-world implementations."
2,"=HYPERLINK(""http://arxiv.org/abs/2411.09178v2"", ""SAFES: Sequential Privacy and Fairness Enhancing Data Synthesis for
  Responsible AI"")","As data-driven and AI-based decision making gains widespread adoption in most
disciplines, it is crucial that both data privacy and decision fairness are
appropriately addressed. While differential pr...",http://arxiv.org/pdf/2411.09178v2.pdf,Spencer Giddens,3.0,Fang Liu,131.0,81.307816,2024-11-14T04:36:12Z,Responsible AI,"The paper, ""SAFES: Sequential Privacy and Fairness Enhancing Data Synthesis for Responsible AI"", by Spencer Giddens and Fang Liu, proposes a new methodology called SAFES for aiding responsible AI development. As AI decision-making becomes more common, concerns about data privacy and fairness grow. While both issues have been tackled independently, the study presents SAFES as a solution that addresses both simultaneously. It does this by combining data synthesis that ensures privacy, with data transformation that is aware of fairness issues. The team tested SAFES using the 'Adult' and 'COMPAS' datasets, finding that it improved fairness metrics significantly while maintaining reasonable levels of privacy. The research is potentially significant as it addresses a critical gap in the progress toward responsible AI use."
3,"=HYPERLINK(""http://arxiv.org/abs/2411.00437v1"", ""E2E-AFG: An End-to-End Model with Adaptive Filtering for
  Retrieval-Augmented Generation"")","Retrieval-augmented generation methods often neglect the quality of content
retrieved from external knowledge bases, resulting in irrelevant information or
potential misinformation that negatively aff...",http://arxiv.org/pdf/2411.00437v1.pdf,Yun Jiang,78.0,Zilong Xie,14.0,78.49904,2024-11-01T08:02:09Z,Other,"The paper discusses a model named E2E-AFG, an adaptive end-to-end solution for retrieval-augmented generation, intended to improve content quality retrieved from external knowledge bases. The model integrates judgment and text generation to focus on relevant information and reduce the impact of irrelevant data. It's tested on six knowledge-intensive language datasets and shows consistent superior performance over baseline models. The model addresses the problem of large language models generating inaccurate content due to the neglect of content quality in retrieval-augmented generation. Real-world impact could include more relevant, accurate responses from AI models in various applications involving large language models."
4,"=HYPERLINK(""http://arxiv.org/abs/2411.02832v2"", ""PersianRAG: A Retrieval-Augmented Generation System for Persian Language"")","Retrieval augmented generation (RAG) models, which integrate large-scale
pre-trained generative models with external retrieval mechanisms, have shown
significant success in various natural language pr...",http://arxiv.org/pdf/2411.02832v2.pdf,Hossein Hosseini,57.0,Mohammad Sobhan Zare,0.0,70.67438,2024-11-05T06:11:17Z,RAG,"The research aims to tackle challenges in implementing Retrieval-Augmented Generation (RAG) systems for Persian, a low-resource language. The proposed PersianRAG utilizes a unique approach for data preprocessing, embedding, retrieval, generation and hyperparameter optimization tailored to Persian language. The PersianRAG demonstrated its potential to enhance question answering tasks in Persian on several benchmark datasets. RAG systems combine a pre-existing knowledge base and large-scale language models to generate contextually accurate dialogue, making them beneficial in domains such as medicine, law, and science. The findings offer insights for improving natural language processing systems for underrepresented languages."
5,"=HYPERLINK(""http://arxiv.org/abs/2411.02577v1"", ""Where Assessment Validation and Responsible AI Meet"")","Validity, reliability, and fairness are core ethical principles embedded in
classical argument-based assessment validation theory. These principles are
also central to the Standards for Educational an...",http://arxiv.org/pdf/2411.02577v1.pdf,Jill Burstein,51.0,Geoffrey T. LaFlair,13.0,61.633778,2024-11-04T20:20:29Z,Responsible AI,"This research by Jill Burstein and Geoffrey T. LaFlair from Duolingo, Inc. addresses the issue of maintaining ethical principles such as validity, reliability, and fairness in the application of Artificial Intelligence (AI) in high-stakes assessments, such as automated scoring of written and spoken responses. The paper posits the use of Responsible AI (RAI) principles and practices, developed by the AI ethics community, as a solution. The authors propose a unified assessment framework which combines classical test validation theory with assessment-specific and domain-agnostic RAI principles. The presented framework could have a significant impact on how AI is used in educational and psychological testing, by aligning it more closely with human values and responsibilities. The implementation of these principles could increase trust in AI's role in assessment processes, maintaining ethical standards and accountability."
6,"=HYPERLINK(""http://arxiv.org/abs/2411.06037v1"", ""Sufficient Context: A New Lens on Retrieval Augmented Generation Systems"")","Augmenting LLMs with context leads to improved performance across many
applications. Despite much research on Retrieval Augmented Generation (RAG)
systems, an open question is whether errors arise bec...",http://arxiv.org/pdf/2411.06037v1.pdf,Hailey Joren,6.0,Jianyi Zhang,103.0,58.572845,2024-11-09T02:13:14Z,Retrieval Augmented Generation,"The study examines how certain language models function when they are provided with adequate or insufficient context. It explores the impact of context on Retrieval Augmented Generation (RAG) systems, highlighting that these systems sometimes fail because of insufficient context. The researchers introduce the concept of 'sufficient context' and develop a method to identify when enough information is available to answer the query. Findings show that proprietary language models (e.g., Gemini, GPT) perform well when sufficient context is provided, but struggle with insufficient context, often producing incorrect answers. On the other hand, open-source models (Llama, Mistral, Gemma) often hallucinate or abstain even with sufficient context. To address these issues, the researchers suggest using ‘sufficient context labels’ to reduce model hallucinations and introduce a new selective generation framework to improve accuracy. This work could significantly improve understanding and performance of language models, avoiding incorrect or ambiguous responses in various applications."
7,"=HYPERLINK(""http://arxiv.org/abs/2411.03957v1"", ""Fine-Grained Guidance for Retrievers: Leveraging LLMs' Feedback in
  Retrieval-Augmented Generation"")","Retrieval-Augmented Generation (RAG) has proven to be an effective method for
mitigating hallucination issues inherent in large language models (LLMs).
Previous approaches typically train retrievers b...",http://arxiv.org/pdf/2411.03957v1.pdf,Yuhang Liu,40.0,Xueyu Hu,13.0,56.426155,2024-11-06T14:42:39Z,RAG,"The research discusses an enhancement to current methods of generating text using large language models (LLMs) which often produce false or hallucinatory data. The Retrieval-Augmented Generation (RAG) method, which borrows information from external sources to improve LLMs, is improved with a framework called FiGRet. FiGRet improves RAG by assisting 'retrievers' (minor text generation models) to understand the retrieval objectives of LLMs. It focuses on enhancing relevance, comprehensiveness, and purity of the retrieved data. The research suggests that by adopting this framework, the performance of RAG systems with various retrievers can be significantly improved."
8,"=HYPERLINK(""http://arxiv.org/abs/2411.08320v1"", ""Responsible AI in Construction Safety: Systematic Evaluation of Large
  Language Models and Prompt Engineering"")","Construction remains one of the most hazardous sectors. Recent advancements
in AI, particularly Large Language Models (LLMs), offer promising opportunities
for enhancing workplace safety. However, res...",http://arxiv.org/pdf/2411.08320v1.pdf,Farouq Sammour,4.0,Jia Xu,66.0,43.902153,2024-11-13T04:06:09Z,Responsible AI,"The construction industry remains quite hazardous, and there's a need for robust safety management, which is where AI, notably large language models (LLMs), come in. A study by researchers at Texas A&M University explores the use of two LLMs, GPT-3.5 and GPT-4o, in enhancing construction site safety. The findings? Both models perform well in safety management and hazard identification, with the GPT-4o model having an 84.6% accuracy rate and the GPT-3.5 model scoring 73.8%. However, there are shortcomings in emergency response and fire prevention, resulting from limitations like lack of knowledge and calculation errors. By identifying LLMs' strengths and weaknesses, construction safety can be improved, potentially leading to a reduction in injuries. The use of 'prompt engineering strategies' can enhance the application of LLMs- this entails giving clear instructions to guide the models in generating accurate results."
9,"=HYPERLINK(""http://arxiv.org/abs/2410.20833v1"", ""LLMs are Biased Evaluators But Not Biased for Retrieval Augmented
  Generation"")","Recent studies have demonstrated that large language models (LLMs) exhibit
significant biases in evaluation tasks, particularly in preferentially rating
and favoring self-generated content. However, t...",http://arxiv.org/pdf/2410.20833v1.pdf,Yen-Shan Chen,0.0,Jing Jin,72.0,43.119617,2024-10-28T08:32:09Z,Other,"Researchers from National Taiwan University studied the biases of large language models (LLMs) within retrieval-augmented generation (RAG) frameworks, where factual precision is prioritized over stylistic features. They simulated aspects of the RAG process, testing if the LLMs favored their own self-generated content. Their study found no significant bias within RAG frameworks. In fact, they discovered that facts greatly influence LLM outputs, even with no prior knowledge. The team's findings indicate the RAG system could provide a solution to LLM bias, aiding the creation of robust, unbiased language AI systems."
10,"=HYPERLINK(""http://arxiv.org/abs/2410.22954v1"", ""Retrieval-Augmented Generation with Estimation of Source Reliability"")","Retrieval-augmented generation (RAG) addresses key limitations of large
language models (LLMs), such as hallucinations and outdated knowledge, by
incorporating external databases. These databases typi...",http://arxiv.org/pdf/2410.22954v1.pdf,Jeongyeon Hwang,19.0,Junyoung Park,40.0,40.37591,2024-10-30T12:09:29Z,Other,"This research explores the advancement of Retrieval-Augmented Generation (RAG), a tool that makes large language models more up-to-date by drawing from external databases. The researchers noticed an issue with RAG, as it often neglects to discern source reliability. This means data could be sourced from a mix of credible and dubious sources, risking misinformation. They proposed Reliability-Aware RAG (RA-RAG), which can estimate the trustworthiness of a source and weigh this in the information retrieval process. RA-RAG uses an iterative estimation process for source reliability and retrieval. It highlights documents from the most reliable sources and conducts a weighted majority vote to select relevant documents. Furthermore, it includes a filtering mechanism to avoid misinformation. The researchers found that RA-RAG significantly outperformed other models, indicating its effectiveness in generating accurate and reliable information."
11,"=HYPERLINK(""http://arxiv.org/abs/2411.13691v1"", ""Retrieval-Augmented Generation for Domain-Specific Question Answering: A
  Case Study on Pittsburgh and CMU"")","We designed a Retrieval-Augmented Generation (RAG) system to provide large
language models with relevant documents for answering domain-specific questions
about Pittsburgh and Carnegie Mellon Universi...",http://arxiv.org/pdf/2411.13691v1.pdf,Haojia Sun,32.0,Yaqi Wang,26.0,37.38018,2024-11-20T20:10:43Z,Other,"Researchers at Carnegie Mellon University developed a Retrieval-Augmented Generation (RAG) system to answer specific questions about Pittsburgh and the university by providing relevant documents to large language models. They used Greedy Scraping strategy to extract over 1,800 subpages and combined manual and Mistral-generated question-answer pairs to achieve an inter-annotator agreement (IAA) score of 0.7625. In experiments, the RAG system significantly outperformed a non-RAG baseline, especially on complex, time-sensitive queries, demonstrating its potential to enhance answer precision and relevance."
12,"=HYPERLINK(""http://arxiv.org/abs/2411.00744v1"", ""CORAG: A Cost-Constrained Retrieval Optimization System for
  Retrieval-Augmented Generation"")","Large Language Models (LLMs) have demonstrated remarkable generation
capabilities but often struggle to access up-to-date information, which can
lead to hallucinations. Retrieval-Augmented Generation ...",http://arxiv.org/pdf/2411.00744v1.pdf,Ziting Wang,20.0,Haitao Yuan,21.0,29.435844,2024-11-01T17:11:16Z,RAG,"The paper discusses ""CORAG,"" a cost-constrained retrieval optimization system developed so Language Learning Models (LLMs) could access up-to-date information through chunk-specific external databases. This system uses Monte Carlo Tree Search (MCTS) for chunk retrieval and addresses key challenges: chunk correlation oversight, non-monotomic utility (adding more chunks decreases overall utility), and handling unique user query characteristics. A configuration agent within the system also predicts optimal configurations for each query type for improved adaptability and efficiency. Test results display an improvement rate of up to 30% over baseline models."
13,"=HYPERLINK(""http://arxiv.org/abs/2411.07773v1"", ""Likelihood as a Performance Gauge for Retrieval-Augmented Generation"")","Recent work finds that retrieval-augmented generation with large language
models is prone to be influenced by the order of retrieved documents in the
context. However, the lack of in-depth analysis li...",http://arxiv.org/pdf/2411.07773v1.pdf,Tianyu Liu,28.0,Jirui Qi,3.0,22.10207,2024-11-12T13:14:09Z,Other,"Scientists discover that retrieval-augmented language models (computers that scan and generate textual responses to human prompts) can perform better or worse depending on the order they encounter information. Using two datasets, the team adjusted the position of ""gold,"" or correct, content within the models’ queue. They found that these models performed best when the gold content was either first or last in the queue - a ""U-shaped"" trend with poorer performance in the middle. Based on this, they proposed two techniques to use position and performance likelihood to improve a model's performance. Their methods offer promise for improving language model efficiency and accuracy when performing tasks like answering questions."
14,"=HYPERLINK(""http://arxiv.org/abs/2411.04994v1"", ""Public Procurement for Responsible AI? Understanding U.S. Cities'
  Practices, Challenges, and Needs"")","Most AI tools adopted by governments are not developed internally, but
instead are acquired from third-party vendors in a process called public
procurement. While scholars and regulatory proposals hav...",http://arxiv.org/pdf/2411.04994v1.pdf,Nari Johnson,5.0,Elise Silva,40.0,19.080986,2024-11-07T18:58:16Z,Responsible AI,"Scholars from the Carnegie Mellon University investigated the process and challenges involved in public procurement of AI technologies by US cities in an effort to improve and encourage responsible AI governance practices. Through interviews with 18 city employees across 7 US cities, they found that AI tools often bypass traditional procurement processes, impeding oversight and governance. The researchers identified five major areas of challenges faced by these employees in securing responsible AI, including minimal visibility into AI usage, organizational challenges, insufficient skills to evaluate AI risks, unbalanced vendor relationships, and tension involving direct stakeholders. The researchers proposed practical recommendations to aid government officials, researchers, and policymakers in addressing these challenges, encouraging more responsible use of AI technologies in the public sector. The real-world impact of these findings may lead to improved oversight, governance practices, and responsible use of AI technologies in public service sectors."
15,"=HYPERLINK(""http://arxiv.org/abs/2410.20142v1"", ""Mask-based Membership Inference Attacks for Retrieval-Augmented
  Generation"")","Retrieval-Augmented Generation (RAG) has been an effective approach to
mitigate hallucinations in large language models (LLMs) by incorporating
up-to-date and domain-specific knowledge. Recently, ther...",http://arxiv.org/pdf/2410.20142v1.pdf,Mingrui Liu,18.0,Sixiao Zhang,6.0,18.85537,2024-10-26T10:43:39Z,Other,"Mingrui Liu, Sixiao Zhang, and Cheng Long, researchers at Nanyang Technological University in Singapore, have addressed the problem of identifying if a specific document is stored in a Retrieval-Augmented Generation (RAG) system's database. To solve this, they proposed a Mask-Based Membership Inference Attacks (MBA) framework. It works by masking parts of the target document and then asking the RAG system to predict the masked values. If the system accurately predicts these values, it means the document exists in the knowledge database. Their experiments showed that this method was more effective than existing models. This research helps increase the trustworthiness of RAG systems, which are often used for large language models in areas like commercial question-and-answer systems."
